{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e1d3a2c",
   "metadata": {},
   "source": [
    "# Text classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de70047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aaed33",
   "metadata": {},
   "source": [
    "- fundamental task in Natural Language Processing (NLP)\n",
    "- categorizing text into organized groups\n",
    "- used for spam detection, sentiment analysis, tagging customer queries, document categorization, news categorization, and much more\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b367f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url= \"../img/classification.png\")\n",
    "# https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51966d63",
   "metadata": {},
   "source": [
    "### Machine learning and NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eac8c1",
   "metadata": {},
   "source": [
    "- a supervised learning approach where observed and labeled text data is used to train a classifier model\n",
    "- the trained model is then used to predict the class of new, unseen text data.\n",
    "\n",
    "### Algorithms used for text classification:\n",
    "* Naive Bayes\n",
    "* Logistic Regression\n",
    "* Support Vector Machines\n",
    "* Random Forests\n",
    "* Gradient Boosting algorithms, \n",
    "* deep learning models such as Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bc8fb8",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786dfd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38510944",
   "metadata": {},
   "source": [
    "Our dataset now has also the categories of topics. Our aim is to be able to classify any new text that we get, automatically into these five categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a710b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/bbc-text-categories.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dace9d",
   "metadata": {},
   "source": [
    "### Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc53407",
   "metadata": {},
   "source": [
    "The first step, as before is the text preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15508afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4635fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove punctuations and numbers\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove single characters\n",
    "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
    "    # Lemmatize and remove stopwords\n",
    "    text = [lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c79f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344ce176",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Exercise 1</b>\n",
    "\n",
    "\n",
    "  <li>Split the data (processed_text and category) into train and test sets </li>\n",
    "  <li> Make the test- train distribution 80-20</li>\n",
    "\n",
    "\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c091e85",
   "metadata": {},
   "source": [
    "### Vectorizing the text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbdcdda",
   "metadata": {},
   "source": [
    "In the case of our text classification task, we use vectorization to convert the news text into a format that our machine learning models can understand and learn from.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0cafb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94a4ed0",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1100e3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Exercise 1</b>\n",
    "\n",
    "\n",
    "  <li> Train and evaluate Logistic Regression</li>\n",
    "  <li> use metrics.accuracy_score for the evaluation</li>\n",
    "\n",
    "\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb116755",
   "metadata": {},
   "source": [
    "### k-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287f4529",
   "metadata": {},
   "source": [
    "- see Titanic notebook\n",
    "- It doesn't learn a model, it classifies samples based on their similarity to samples seen during trainin\n",
    "- the class of a new sample is determined by the majority class of its K closest samples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e7246",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Exercise 2</b>\n",
    "\n",
    "\n",
    "  <li> Train and evaluate a k-NN algoritm</li>\n",
    "  <li> use metrics.accuracy_score for the evaluation</li>\n",
    "\n",
    "\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c220c008",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134db095",
   "metadata": {},
   "source": [
    "- see Titanic notebook\n",
    "- Support Vector Machine \n",
    "- a powerful classification model that aims to find the best hyperplane separating different classes\n",
    "- works well at untangling outliers from complex small and medium datasets and managing high dimensional data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f84a73",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Exercise 3</b>\n",
    "\n",
    "\n",
    "  <li> Train and evaluate an SVM algoritm</li>\n",
    "  <li> use metrics.accuracy_score for the evaluation</li>\n",
    "\n",
    "\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1145c3f8",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c811ce",
   "metadata": {},
   "source": [
    "- Naive Bayes is a classification algorithm based on applying Bayes' theorem with a strong assumption that all the predictors (or features) are independent of each other - this  is what makes it 'naive'\n",
    "\n",
    "- Bayes' theorem is a fundamental theorem in the field of probability theory and statistics that describes the probability of an event based on prior knowledge of conditions that might be related to the event.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59316f49",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71678f8e",
   "metadata": {},
   "source": [
    "We are trying to classify an email as spam or not spam based on the words in the email. The 'naive' assumption allows us to estimate the probability of each word appearing in a spam email independently.\n",
    "\n",
    "For instance, let's assume we have two words, 'free' and 'offer'. If both these words appear in an email, under the 'naive' assumption, we assume that the appearance of 'free' does not affect the appearance of 'offer' and vice versa, even though it's possible that 'free' and 'offer' might often appear together in spam emails.\n",
    "\n",
    "Despite this 'naive' assumption, Naive Bayes classifiers work quite well in many real-world situations, especially for text classification problems like spam detection, sentiment analysis, and topic categorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58007b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url= \"../img/BAYES.png\", height = 100, width=500)\n",
    "# https://www.turing.com/kb/an-introduction-to-naive-bayes-algorithm-for-beginners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5edad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_naive_bayes = MultinomialNB()\n",
    "clf_naive_bayes.fit(X_train, y_train)\n",
    "pred = clf_naive_bayes.predict(X_test)\n",
    "print('Naive Bayes Accuracy:', metrics.accuracy_score(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3cc389",
   "metadata": {},
   "source": [
    "### Making a prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef13660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"The government announced new policies on international trade. The stock market responded positively to the news. Tech companies are expecting to benefit from these changes. Sports events will be affected due to the adjustments in international travel policies.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc906b68",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Exercise 4</b>\n",
    "\n",
    "\n",
    "  <li> preprocess our new text using the preprocess funciton</li>\n",
    "  <li> vectorize our text</li>\n",
    "\n",
    "\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82111dbe",
   "metadata": {},
   "source": [
    "### Make predictions with each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abf2732",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_pred = clf.predict(example_vectorized)\n",
    "knn_pred = clf_knn.predict(example_vectorized)\n",
    "svm_pred = clf_svm.predict(example_vectorized)\n",
    "naive_bayes_pred = clf_naive_bayes.predict(example_vectorized)\n",
    "\n",
    "print(\"Logistic Regression Prediction: \", log_reg_pred[0])\n",
    "print(\"KNN Prediction: \", knn_pred[0])\n",
    "print(\"SVM Prediction: \", svm_pred[0])\n",
    "print(\"Naive Bayes Prediction: \", naive_bayes_pred[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
