{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee35153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b49adf",
   "metadata": {},
   "source": [
    "Let's start like before, by reading in our .csv. \n",
    "This time, it deals with supemarket sales ans has information on the purchases made, such as the type of the shopper, the gender, the price and quantity of items, the product line, etc. We also get info on the city in which the purchase has been made and the rating (review) of the purchase. Can you think of some research questions that we can pose, knowing we have this information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2a375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('data/supermarket_sales.csv')\n",
    "sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b1bf72",
   "metadata": {},
   "source": [
    "### Let's explore our dataset a little bit\n",
    "To get a feel for the dataset, we can take a look at the column names and the first ten entries. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062ee22d",
   "metadata": {},
   "source": [
    "```head()``` usually shows us the first five rows of the data, but we can also extend that by specifying the number of rows we are interested in as a parameter of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e72bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cfeb29",
   "metadata": {},
   "source": [
    "We can also take a random sample from the dataset using the ```sample()``` method. As a parameter, we specify how big of a sample we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074356c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48feb0e",
   "metadata": {},
   "source": [
    "We can also check the shape of the DataFrame and the number of unique entries per column. The latter values are considered to be \"categorical data\", because they sort data in categories or groups. Which columns in our dataset can be considered categorical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674bca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94152caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Product line'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d4bd6f",
   "metadata": {},
   "source": [
    "We can also check a specific entry (here by using indexing) to see an example entry from our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a823c71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.iloc[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3d83f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.Gender.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad0a69e",
   "metadata": {},
   "source": [
    "We can also check the nr of entries in which the customer was a male:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056327eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_male = sales[sales['Gender']=='Male']\n",
    "sales_male.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce2b051",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_female = sales[sales['Gender']=='Female']\n",
    "sales_female.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5675819",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' Purchases made by people identifying as male: {sales_male.shape} \\n Purchases made by people identifying as female: {sales_female.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef36cd1b",
   "metadata": {},
   "source": [
    "We can see our dataset is pretty balanced when it comes to the categorical variable of gender."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0dbf71",
   "metadata": {},
   "source": [
    "Or the nr of entries where the total sum of the invoice was less than 100 e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7991ea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[sales['Total'] < 100].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13216240",
   "metadata": {},
   "source": [
    "Using shape() we check the number of rows that have the total amount less than a 100 e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444a3d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[sales['Total'] < 100].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5298b797",
   "metadata": {},
   "source": [
    "Then, we can do the same for over 100 e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1a016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[sales['Total'] > 100].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b974a839",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[sales['Total'] > 100].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfb9e33",
   "metadata": {},
   "source": [
    "We immidiately can concude by the nr of entries, that most common were the purchases totalling over 100 e (783 vs 205)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effcd217",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Payment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7eed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[sales['Payment']=='Cash'].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b381df10",
   "metadata": {},
   "source": [
    "Now, if we wanted to continue playing around, we could do the same for Payment and check the number of entries in each category. We can also try reading that from a plot later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a4abb1",
   "metadata": {},
   "source": [
    "### Dataset cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6132f9",
   "metadata": {},
   "source": [
    "In order to draw any conclusions from our data, our dataset must be clean and balanced.\n",
    "This can mean different things for different scenarios. At this point, let's just say that we need to figure out how to handle the duplicate entries that might skew our analyses;  what to do with the empty cells and how to change the datatype of the cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c95133",
   "metadata": {},
   "source": [
    "#### Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04532ea",
   "metadata": {},
   "source": [
    "Let's take a look at what the funciton ```duplicated()``` does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456b2585",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sales.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb77e5a9",
   "metadata": {},
   "source": [
    "We can also separate the duplicated rows in another dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce6823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicateRows = sales[sales.duplicated()]\n",
    "duplicateRows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b388b781",
   "metadata": {},
   "source": [
    "There are multiple ways of dealing with duplicates, e.g.\n",
    "\n",
    "\n",
    "```\n",
    "df.drop_duplicates (inplace=True) \n",
    "\n",
    "```\n",
    "\n",
    "which makes sure that we are not creating a new dataframe but that the dupicates are removed from the old one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0c7fdb",
   "metadata": {},
   "source": [
    "We can also use \n",
    "```\n",
    "df = df[df.duplicated(keep='last')]\n",
    " \n",
    "```\n",
    "\n",
    "which keeps the last occurence of the duplicate\n",
    "\n",
    "or \n",
    "\n",
    "```\n",
    "df = df[df.duplicated(keep='first')]\n",
    "```\n",
    "\n",
    "which keeps the first occurence of the duplicate.\n",
    "\n",
    "In these cases, we need to store it to a new dataframe variable, otherwise it won't be applied to the dataframe permanently (unlike with the drop_duplicates() function).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd3e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[sales.duplicated(keep='last')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7442da81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a966d9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd8b80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b533e724",
   "metadata": {},
   "source": [
    "-- We see that the nr of rows diminished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89739697",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cede2d",
   "metadata": {},
   "source": [
    "We can also uss the parameter ```keep``` with the ```drop_duplicates()``` function (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55dc2d8",
   "metadata": {},
   "source": [
    "#### Empty cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dc55a6",
   "metadata": {},
   "source": [
    "One way to deal with empty cells is to remove rows that contain empty cells. This is usually fine, since data sets can be very big, and removing a few rows will not have a big impact on the result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc914461",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[sales.isna().any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033836f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[sales['Branch'].isna()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71604dcb",
   "metadata": {},
   "source": [
    "We can, for example, fill the empty cell with some other type of value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acfe803",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[\"Branch\"].fillna('A', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3846461",
   "metadata": {},
   "source": [
    "We still have all the other NaN values so let's take care of them. We know we have (at least) one NaN in the Tax 5% column. Let's fill that out by calculating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578de098",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_tax = sales.Total * 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a728ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[\"Tax 5%\"].fillna(sales_tax, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b9a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7518890",
   "metadata": {},
   "source": [
    "As we see, the 'Tax 5%' column was filled in by the content of the variable ```sales_tax```, i.e. 4.011 (80.22 * 0.05).\n",
    "We can also use functions like ```mean()```, ```max()```, ```min()``` and  ```mode()``` to fill out the empty values. The first three you are familiar with and ```mode()``` fills out the empty space with the most frequent value in the column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041efbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_payement = sales['Payment'].mode()\n",
    "mode_payement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9047b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_payement = sales['Payment'].mode()[0]\n",
    "mode_payement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1128c44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[\"Payment\"].fillna(mode_payement, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb63607",
   "metadata": {},
   "source": [
    "Or, we can always just remove the rows with the empty cells, or create a new dataframe that has no empty cells.\n",
    "We do that through the ```dropna()``` function. If we use it without parameters, it will return a new DataFrame, while if we use the ```inplace = True``` parameter, it will change the original one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49faf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9715c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4c39c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75578c6",
   "metadata": {},
   "source": [
    "In the end, we have lost 7 rows which had NaN values in them, and now our dataframe should be NaN-free:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7902c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[sales.isna().any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1061f11b",
   "metadata": {},
   "source": [
    "#### Wrong type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92309527",
   "metadata": {},
   "source": [
    "Cells with data of wrong datatype can make it difficult to analyze data.\n",
    "\n",
    "To fix it, you have two options: remove the rows, or convert all cells in the columns into the same format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fb8cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f22b75",
   "metadata": {},
   "source": [
    "We have a problem with the quantity. It's a float, but we can never buy two and a half items or smth like that. So we need to cast it to an int. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd57ff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.Quantity = sales.Quantity.astype(int)\n",
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afc5791",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Unit price']= pd.to_numeric(sales['Unit price'], errors='coerce')\n",
    "sales = sales.replace(np.nan, 0, regex=True)\n",
    "print(sales.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa754ae5",
   "metadata": {},
   "source": [
    "Same with the date and time - they're objects (which stands for a string) and not actually date and time. So let's change that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f34e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.Date = pd.to_datetime(sales.Date)\n",
    "\n",
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1936190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DataFrame.apply() to convert multiple columns to datetime\n",
    "sales[['Date','Time']] = sales[['Date','Time']].apply(pd.to_datetime)\n",
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5212fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d17d7f7",
   "metadata": {},
   "source": [
    "#### Digression - apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0aeeda",
   "metadata": {},
   "source": [
    "apply() is a useful function used to apply (:D) a function along an axis of the DataFrame,  default 0, which is the index (row) axis.\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419f511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sum(x):\n",
    "    return x.sum()\n",
    "\n",
    "data = {\n",
    "  \"x\": [50, 40, 30],\n",
    "  \"y\": [300, 1112, 42]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "x = df.apply(calc_sum)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5500a75",
   "metadata": {},
   "source": [
    "### Query methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b917637",
   "metadata": {},
   "source": [
    "We already saw that if we find the unique categories in a categorical variable, we can figure out the number of rows depending on a condition (e.g. name of the city). However, sometimes we want to use multiple conditions, and for that we use ```query()```. It automatically returns a new dataframe, but if we want to just update the existing one, we would use ```inplace = True``` as the argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cd77f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['City'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1402ba0b",
   "metadata": {},
   "source": [
    "* purchases made in Yangon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838c5ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.query('City == \"Yangon\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a826792",
   "metadata": {},
   "source": [
    "* purchases made in Yangon in cash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a9cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.query('City == \"Yangon\" & Payment == \"Cash\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082d370d",
   "metadata": {},
   "source": [
    "* purchases totalling between 1500 and 1000 e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.query('1000 < Total < 1500')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe3a121",
   "metadata": {},
   "source": [
    "* purchases made in Naypyitaw in cash, that cost less than 50e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434f0d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.query('Payment == \"Cash\" & City ==\"Naypyitaw\" & Total < 50')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d83ec2",
   "metadata": {},
   "source": [
    "### Sum, Max, Min and Average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6defef",
   "metadata": {},
   "source": [
    "We can also of course, use functions like ```min()```, ```max()```,```sum()``` and ```mean()``` for basic statistical operations. We can also use ```describe()``` for a glance of the complete statistics of the data in a df or a particular column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5f7ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Total'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05addb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.mean() ['Quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e70f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f0077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[sales['Total']== sales.max()['Total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ae62b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[sales['Total']== sales.min()['Total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c2fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9e713f",
   "metadata": {},
   "source": [
    "### Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c289b590",
   "metadata": {},
   "source": [
    "Let's say we had another .csv that we wanted to add to ours. We would do that in pandas in three ways:\n",
    "* merge() -  for combining data on common columns or indices\n",
    "* join() - for combining data on a key column or an index\n",
    "* concat() - for combining DataFrames across rows or columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ff04e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "addition = pd.read_csv('data/addition.csv')\n",
    "addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0036778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "addition.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec0e1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [sales, addition]\n",
    "sales = pd.concat(dataframes)\n",
    "sales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde21d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac243b12",
   "metadata": {},
   "source": [
    "Here the situation is really simple, because we have two dataframes with the same column names. However, the situation can get far more complicated in many cases. I would <b> strongly </b> suggest you read: https://pandas.pydata.org/docs/user_guide/merging.html on all types of merging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc553265",
   "metadata": {},
   "source": [
    "### Groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03a441a",
   "metadata": {},
   "source": [
    "```groupby()``` is used to group the data into categories and apply functions to the categories. It can form groups based on one or more conditions. It can also be used on more than one DataFrames in order to find common categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6ff479",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.groupby('City').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c620a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.groupby('Customer type').sum()['Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b967c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.groupby(['Customer type']).agg({'Total': 'sum'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff239f00",
   "metadata": {},
   "source": [
    "<b> Digression:</b> \n",
    "- ```agg()``` - the method allows you to apply a function or a list of function names to be executed along one of the axis of the DataFrame, default 0, which is the index (row) axis \n",
    "     * (https://www.w3schools.com/python/pandas/ref_df_agg.asp)\n",
    "\n",
    "-  ```count()``` - another useful function - count the number of (not NULL) values in each row                            \n",
    "      * (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.count.html)\n",
    "-  ```unstack()``` - used to reshape the given Pandas DataFrame by transposing specified row level to column level \n",
    "     *   (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.unstack.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6528bb2",
   "metadata": {},
   "source": [
    "## Let's answer some questions\n",
    "### Also called \"<i>Exploratory data analysis (EDA) </i>\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4445901",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Exercises</b>\n",
    "<p>\n",
    "    <li>1. Which city has more male shoppers?</li>\n",
    "    <li>2. Who spends more, men or women (in this particular dataframe)?</li>\n",
    "    <li>3. Which type of customer spends more, member or non- member?    </li>\n",
    "    <li>4. Which product line sells the most?</li>\n",
    "    <li>5. Which product line is popular among men or women?</li>\n",
    "    <li>6. What day of month makes the highest sales?</li>\n",
    "    <li>7. What month makes the highest sales?</li>\n",
    "    <li>8. Find the highest unit price in the product line.</li>\n",
    "    <li>9. Find the most popular payment method used by customers</li>\n",
    "    <li>10. Find the payment method that lead to the most amount of money per branch</li>\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "</p>\n",
    "  \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c41c77b",
   "metadata": {},
   "source": [
    "1. Which city has more male shoppers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c76fb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_shoppers = sales.groupby(['City', 'Gender']).count()['Invoice ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c869c442",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_shoppers.unstack(level = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0deb35",
   "metadata": {},
   "source": [
    "If we want to use matplotlib, we only need to add to this line and we get a bar plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a435b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_shoppers.unstack(level = 0).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85d6cb5",
   "metadata": {},
   "source": [
    "We can always use our standard libraries for plots, such as matplotlib(https://matplotlib.org/) or seaborn(https://seaborn.pydata.org/index.html). Make sure to investigate them to be able to pick which one you like. I personally, like plotly (https://plotly.com/graphing-libraries/).\n",
    "\n",
    "To be able to use it, you need to ofc install it. It's available in Anaconda Navigator, but othewise, we can install it in the Anaconda Prompt by typing\n",
    "\n",
    "```\n",
    "$ conda install -c plotly plotly=5.14.1\n",
    " \n",
    "```\n",
    "\n",
    "or in the Terminal \n",
    "\n",
    "```\n",
    "$ pip install plotly==5.14.1\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6240fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33910ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(sales, x = 'Gender', y = 'Invoice ID',\n",
    "                     hover_name = 'City',color = 'City')\n",
    "\n",
    "fig.update_layout({\n",
    "'plot_bgcolor': 'rgba(0, 0, 0, 0)',\n",
    "'paper_bgcolor': 'rgba(0, 0, 0, 0)',\n",
    "'title': 'city with more male shoppers'})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dda242",
   "metadata": {},
   "source": [
    "2. Who spends more, men or women (in this particular dataframe)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59747d4",
   "metadata": {},
   "source": [
    "3. Which type of customer spends more, member or non- member?    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f3cd3a",
   "metadata": {},
   "source": [
    "4. Which product line sells the most?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e76ae13",
   "metadata": {},
   "source": [
    "5. Which product line is popular among men or women?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be22f6f9",
   "metadata": {},
   "source": [
    "6. What day of month makes the highest sales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4207216",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Day'] = sales['Date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2ae02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90230f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_sales = sales.groupby('Day').sum()['Total']\n",
    "day_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5ee232",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_sales.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc29b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_sales_df = day_sales.to_frame().reset_index()\n",
    "day_sales_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70c8c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(day_sales_df, x='Day', y=\"Total\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc24b979",
   "metadata": {},
   "source": [
    "7. Which month makes the most sales?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305463c2",
   "metadata": {},
   "source": [
    "8. Find the highest unit price in the product line.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1508517",
   "metadata": {},
   "source": [
    "9. Find the most popular payment method used by customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7ceadc",
   "metadata": {},
   "source": [
    "10. Find the payment method that lead to the most amount of money per branch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407d97c7",
   "metadata": {},
   "source": [
    "### References and literature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872dfc03",
   "metadata": {},
   "source": [
    "- Source of dataset - https://www.kaggle.com/datasets/aungpyaeap/supermarket-sales\n",
    "- W3Schools Pandas Tutorial - https://www.w3schools.com/python/pandas/default.asp\n",
    "- Data Science Handbook: https://jakevdp.github.io/PythonDataScienceHandbook/\n",
    "- more EDA on this dataset - https://www.kaggle.com/code/bharadwajnalla/sales-exploratory-data-analysis\n",
    "- good tutorial on Meidum - https://medium.com/ds-notes/learning-python-pandas-in-minutes-part-1-basics-f24463da1a18\n",
    "- good tutorial on GitHub - https://github.com/alod83/data-science"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
